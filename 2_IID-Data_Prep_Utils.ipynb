{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"IID_Data_Prep_Utils.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"cells":[{"cell_type":"markdown","metadata":{"id":"HdD12O1FUhmb"},"source":["# Data Preparation "]},{"cell_type":"code","metadata":{"id":"SIGTQsz5K_Ln","executionInfo":{"status":"ok","timestamp":1600515765692,"user_tz":-330,"elapsed":10387,"user":{"displayName":"iid deep","photoUrl":"","userId":"09489943153812999005"}},"outputId":"8ecd0e2d-f3fc-49d3-e560-b7c06d5e4e81","colab":{"base_uri":"https://localhost:8080/","height":310}},"source":["# installing required Packages\n","!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n","!pip install gputil\n","!pip install psutil\n","from IPython.display import clear_output\n","clear_output(wait=True)\n","from tensorflow.python.client import device_lib\n","print(device_lib.list_local_devices()[0]) # Cpu info\n","print(device_lib.list_local_devices()[3]) # Gpu info"],"execution_count":null,"outputs":[{"output_type":"stream","text":["name: \"/device:CPU:0\"\n","device_type: \"CPU\"\n","memory_limit: 268435456\n","locality {\n","}\n","incarnation: 15758961345302667866\n","\n","name: \"/device:GPU:0\"\n","device_type: \"GPU\"\n","memory_limit: 15695549568\n","locality {\n","  bus_id: 1\n","  links {\n","  }\n","}\n","incarnation: 8700166528683381238\n","physical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"CUWu-CdAUhmk"},"source":["### Importing all required modules"]},{"cell_type":"code","metadata":{"id":"xBlo-gaMVQRH","outputId":"1f508ced-f270-4002-ad98-2e14fc529577","colab":{"base_uri":"https://localhost:8080/","height":118}},"source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import backend as K\n","from numpy import asarray,zeros,moveaxis\n","import matplotlib.pyplot as plt\n","from sys import getsizeof\n","from tqdm import tqdm\n","import numpy as np\n","import pandas as pd\n","from os import path\n","from tensorflow.keras.initializers import *\n","from tensorflow.keras.models import *\n","from tensorflow.keras.layers import *\n","from tensorflow.keras.callbacks import *\n","from tensorflow.keras.optimizers import *\n","import os,sys,ntpath,fnmatch,shutil,cv2,gc\n","import joblib,time,os.path,itertools\n","from scipy.sparse import csc_matrix\n","from sklearn.utils import shuffle\n","from time import time\n","np.random.seed(0)\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","from google.colab import drive\n","drive.mount('/content/drive')\n","if __name__ != '__main__':clear_output()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"F5RGyKGNUhmp"},"source":["### Function for Memory Utilization status "]},{"cell_type":"code","metadata":{"id":"3OfZz2dkrPIH","outputId":"30e7e707-0a8c-4608-d114-01f956711e89","colab":{"base_uri":"https://localhost:8080/","height":66}},"source":["def get_gpu_memory_status(print_status=False):\n","    \n","    \"\"\"\n","    Function to print the amount of CPU and GPU Memory used at an instant\n","    Input  : print_status <Boolean>\n","    Return : Cpu memory Usage <Float>   \"\"\"\n","\n","    # ref: https://stackoverflow.com/questions/48750199/google-colaboratory-misleading-information-about-its-gpu-only-5-ram-available\n","    \n","    import psutil, os, GPUtil as GPU\n","    GPUs = GPU.getGPUs()  # get list of all avaliable gpus\n","    gpu = GPUs[0]  # first Gpu\n","    process = psutil.Process(os.getpid())  # Process id of current process\n","    s = lambda x: np.round(x / (1024**3), 2)  # lambda function to get memory in GB\n","\n","    if print_status:  # print memory utilization\n","        print(\n","            \"\\nGen RAM Free: {0} GB  - Used: {1} GB - Total : {2} GB - Util  {3} % \".\n","            format(\n","                s(psutil.virtual_memory().available),\n","                s(process.memory_info().rss), s(psutil.virtual_memory().total),\n","                np.round(\n","                    s(process.memory_info().rss) * 100 / s(\n","                        psutil.virtual_memory().total), 2)))\n","        print(\n","            \"GPU RAM Free: {0} GB  - Used: {1} GB - Total : {2} GB  - Util  {3} %  \".\n","            format(\n","                np.round(gpu.memoryFree / 1024, 2),\n","                np.round(gpu.memoryUsed / 1024, 2),\n","                np.round(gpu.memoryTotal / 1024, 2),\n","                np.round(gpu.memoryUtil * 100, 2)))\n","\n","    return s(process.memory_info().rss)\n","\n","if __name__ == '__main__': get_gpu_memory_status(True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","Gen RAM Free: 23.95 GB  - Used: 1.06 GB - Total : 25.51 GB - Util  4.16 % \n","GPU RAM Free: 15.55 GB  - Used: 0.34 GB - Total : 15.9 GB  - Util  2.17 %  \n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0WsbMgKGUhmu"},"source":["### Data Generator Choice"]},{"cell_type":"code","metadata":{"id":"Cts7G686Dkf7","outputId":"f5c8c4d9-a3c3-4717-f3c8-d1e4a1209523","colab":{"base_uri":"https://localhost:8080/","height":98}},"source":["if __name__ == '__main__': # get user choice\n","    root='/content/drive/My Drive/Colab Notebooks/'\n","    Choice=int(input(\"Enter your choice for Data Generator (From where should be the Data loaded for each Batch During Training): \\n\\n\\\n","    1.Raw Image Files from Disk(High Time complexity)  2.Default(Recommended)  3.Saved Joblib Data(High Space complexity):\\n\\n>>>\"))\n","    Dump=joblib.dump(Choice,root+\"Choice\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Enter your choice for Data Generator (From where should be the Data loaded for each Batch During Training): \n","\n","1.Raw Image Files from Disk(High Time complexity)  2.Default(Recommended)  3.Saved Joblib Data(High Space complexity):\n","\n",">>>2\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Kt_0G_WGUhmz"},"source":["###  Get list of all data file names of Part1"]},{"cell_type":"code","metadata":{"id":"qBf2cniUN5AG"},"source":["# path of data files Part1\n","root='/content/drive/My Drive/Colab Notebooks/'\n","train_img_path1=root+'IDD_Segmentation/leftImg8bit/train/'\n","train_label_path1=root+'IDD_Segmentation/gtFine/train_label_level1/'\n","train_img_path2=root+'idd20kII/leftImg8bit/train/'\n","train_label_path2=root+'idd20kII/gtFine/train_label_level1/'\n","\n","# list files of data files Part1\n","train_img_files1=sorted(os.listdir(root+'IDD_Segmentation/leftImg8bit/train'))\n","train_label_files1=sorted(os.listdir(root+'IDD_Segmentation/gtFine/train_label_level1'))\n","val_img_files1=sorted(os.listdir(root+'IDD_Segmentation/leftImg8bit/val'))\n","val_label_files1=sorted(os.listdir(root+'IDD_Segmentation/gtFine/val_label_level1'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sQ02_n1EUhm4"},"source":["###  Get list of all data file names of Part2"]},{"cell_type":"code","metadata":{"id":"gB6dZKVrwLtd"},"source":["# path of data files Part1\n","root='/content/drive/My Drive/Colab Notebooks/'\n","val_img_path1=root+'IDD_Segmentation/leftImg8bit/val/'\n","val_label_path1=root+'IDD_Segmentation/gtFine/val_label_level1/'\n","val_img_path2=root+'idd20kII/leftImg8bit/val/'\n","val_label_path2=root+'idd20kII/gtFine/val_label_level1/'\n","\n","# list files of data files Part1\n","train_img_files2=sorted(os.listdir(root+'idd20kII/leftImg8bit/train'))\n","train_label_files2=sorted(os.listdir(root+'idd20kII/gtFine/train_label_level1'))\n","val_img_files2=sorted(os.listdir(root+'idd20kII/leftImg8bit/val'))\n","val_label_files2=sorted(os.listdir(root+'idd20kII/gtFine/val_label_level1'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-ortKIYxUhm9"},"source":["### Image Data preparation"]},{"cell_type":"code","metadata":{"id":"bLQlrUybzYWK","outputId":"387bc303-e8ed-47ce-97e4-34edbdce406c","colab":{"base_uri":"https://localhost:8080/","height":33}},"source":["def Prepare_Image_and_Save(path, name, img_files):\n","    '''\n","    -----------------------------------------------------------\n","    Function to prepare Image data for a given data files\n","        1. Read all images one after another from specifed Directory.   \n","        2. Resize images after reading it to some height and width   \n","        3. Normalize the pixel values in image by dividing by 255  \n","        4. Save Prepared data for future Usage     \n","    -----------------------------------------------------------\n","        Parameters\n","        ----------\n","        path <list of Path>     : List of Absolute Path of images Data files.\n","        name <String>           : File name to save prepared data \n","        img_files <List>        : List of Image data file names \n","    \n","        returns \n","        --------\n","        Boolean<True>  : Indicate successful Data Preparation \n","    -----------------------------------------------------------\n","\n","    '''\n","    height, width, n_classes = 240, 480, 7\n","    image = []\n","    for j in range(len(path)):\n","        for i in tqdm(range(len(img_files[j]))):\n","            img = cv2.imread(path[j] + img_files[j][i])\n","            img = cv2.resize(img, (width, height))\n","            img = np.float32(img) / 255\n","            image.append(img)\n","    print(len(image))\n","    joblib.dump(image, name)\n","    return True\n","\n","# prepare image based on Data generator choice\n","path_s = \"/content/drive/My Drive/prep_train_img_files_save_80\"\n","if __name__ == '__main__' and Choice>1 : \n","    path1 = [root+'IDD_Segmentation/leftImg8bit/train/',root+'idd20kII/leftImg8bit/train/']\n","    path2 = [root+'IDD_Segmentation/leftImg8bit/val/',root+'idd20kII/leftImg8bit/val/']\n","    img_files1,img_files2 = [train_img_files1,train_img_files2],[val_img_files1,val_img_files2]\n","\n","    Indicator1 = Prepare_Image_and_Save(path1,\"/content/drive/My Drive/Colab Notebooks/prep_train_img_files_save\",img_files1)\n","    Indicator2 = Prepare_Image_and_Save(path2,\"/content/drive/My Drive/Colab Notebooks/prep_val_img_files_save\",img_files2)\n","    if Indicator1 and Indicator2: print(\"Data Preparation of Images Successful Done!\")\n","\n","elif __name__ != '__main__':\n","    #if not path.exists(path_s):raise Exception(\"!File not Found: First Run IID_Data_Prep_Utils.ipynb\")\n","    print(\"Checking Status:\\n\"+\"-\"*54+\"\\n1.Image Data Preparation     .. .. .. >>> |Done| <1/5>\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Data Preparation of Images Successful Done!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-hh22uIsUhnC"},"source":["### Label Mask Data preparation"]},{"cell_type":"code","metadata":{"id":"aX1ArN9Pzx4p","outputId":"3eda25e5-7be9-4cc1-b059-68e87ea6b568","colab":{"base_uri":"https://localhost:8080/","height":33}},"source":["def Prepare_Label_and_Save(path, n_classes, name):\n","    '''\n","    -----------------------------------------------------------\n","    Function to prepare Label data for a given data files\n","        1. Read all Mask one after another from specifed Directory.   \n","        2. Resize Mask after reading it to some height and width   \n","        3. Performing one hot ecoding on mask resulting in 3D matrix     \n","        4. Save Prepared data in sparse representation for future Usage     \n","    -----------------------------------------------------------\n","        Parameters\n","        ----------\n","        path <list of Path>     : List of Absolute Path of images Data files.\n","        n_classes <Integer>     : Number of classes in Mask \n","        name <String>           : File name to save prepared data \n","    \n","        returns \n","        --------\n","        Boolean<True>  : Indicate successful Data Preparation \n","    -----------------------------------------------------------\n","\n","    '''\n","    sparse_list = []\n","    for k in range(len(path)):\n","        files = sorted(os.listdir(path[k]))\n","        height, width, n_classes = 240, 480, n_classes\n","        for j in tqdm(range(len(files))):\n","            label = np.zeros((n_classes, height, width), dtype=np.uint8)\n","            img = cv2.imread(path[k] + \"/\" + files[j], cv2.IMREAD_GRAYSCALE)\n","            img1 = cv2.resize(img, (width, height))\n","            for i in range(n_classes):\n","                label[i, :, :] = (img1 == i).astype(np.uint8)\n","            sp_list = []\n","            for i in range(label.shape[0]):\n","                sp_list.append(csc_matrix(label[i]))\n","            sparse_list.append(sp_list)\n","    joblib.dump(sparse_list, name)\n","    return True\n","\n","# prepare Mask based on Data generator choice\n","if __name__ == '__main__' and Choice>1 : \n","  \n","    path1=[root+\"IDD_Segmentation/gtFine/train_label_level1\",root+\"idd20kII/gtFine/train_label_level1\"]\n","    path2=[root+\"IDD_Segmentation/gtFine/val_label_level1\",root+\"idd20kII/gtFine/val_label_level1\"]\n","    Indicator=Prepare_Label_and_Save(path1,7,root+\"data/prep_train_label_files_save1\")\n","    Indicator=Prepare_Label_and_Save(path2,7,root+\"data/prep_val_label_files_save1\")\n","    if Indicator1 and Indicator2: print(\"Data Preparation of Labels Successful Done!\")\n","\n","elif __name__ != '__main__':print(\"2.Label Mask Preparation     .. .. .. >>> |Done| <2/5>\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Data Preparation of Labels Successful Done!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Q47frKqGUhnI"},"source":["### Shuffle prepared Data Samples"]},{"cell_type":"code","metadata":{"id":"mF8jexJtoa45","outputId":"84e5a9ea-6595-42b5-9051-c0d4c38d3c59","colab":{"base_uri":"https://localhost:8080/","height":33}},"source":["def Shuffle_Data(root=\"/content/drive/My Drive/\"):\n","    '''\n","    Function to shuffle data to get rid bias\n","    Input\n","    root<String>  : Absolute Path of Data where it is saved.\n","    \n","    Return\n","    <Boolean>     : True Indicate successful Data Shuffle\n","    '''\n","    \n","    # Shuffle Prepared Image Data\n","    path1, path3=root+\"data/prep_train_img_files_save\", root+\"data/prep_train_label_files_save1\"\n","    if path.exists(path1) and path.exists(path3):\n","        prep_train_img_files_save, prep_train_label_files_save=shuffle(joblib.load(path1),joblib.load(path3),random_state=0)\n","        Dump=joblib.dump(prep_train_img_files_save, path1), joblib.dump(prep_train_label_files_save, path3)\n","        del prep_train_img_files_save, prep_train_label_files_save\n","        Junk= gc.collect() \n","\n","    # Shuffle Prepared Label Mask Data\n","    path2, path4=root+\"data/prep_val_img_files_save\", root+\"data/prep_val_label_files_save1\"\n","    if path.exists(path2) and path.exists(path4):\n","        prep_val_img_files_save, prep_val_label_files_save=shuffle(joblib.load(path2),joblib.load(path4),random_state=0)\n","        Dump=joblib.dump(prep_val_img_files_save, path2), joblib.dump(prep_val_label_files_save, path4)\n","        del prep_val_img_files_save, prep_val_label_files_save\n","        Junk= gc.collect()\n","    \n","    return True\n","\n","# Invoke based on choice \n","if __name__ == '__main__' and Choice>1 : \n","    Indicator=Shuffle_Data()\n","    if Indicator:print(\"Data Shuffle Successful Done!\")\n","\n","elif __name__ != '__main__':print(\"3.Data Shuffling             .. .. .. >>> |Done| <3/5>\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Data Shuffle Successful Done!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pb8W8QWjUhnN"},"source":["### Train Test split on data"]},{"cell_type":"code","metadata":{"id":"MZjVqTPBH5CO","outputId":"12f9f43c-ab90-42c6-98d5-6ba25e9ac525","colab":{"base_uri":"https://localhost:8080/","height":33}},"source":["def Train_Test_Split(root=\"/content/drive/My Drive/\", split=0.8):\n","    '''\n","    Function to perfrom Train test split of data\n","    \n","    Input\n","    root<String>   : Absolute Path of Data where it is saved.\n","    split<Float>   : Value specify split size of train data\n","    \n","    Return\n","    <Boolean>      : True Indicate successful Train Test Split\n","    '''\n","  \n","    total_no_samples=14027\n","    split_index=(int((total_no_samples*0.8)/32))*32\n","    \n","    path1, path3= root+\"data/prep_train_img_files_save\", root+\"data/prep_train_label_files_save1\"\n","    prep_train_img_files_save, prep_train_label_files_save=joblib.load(path1), joblib.load(path3)\n","    \n","    joblib.dump(prep_train_img_files_save[:split_index], root+\"/prep_train_img_files_save_80\")\n","    joblib.dump(prep_train_label_files_save[:split_index], root+\"/prep_train_label_files_save_80\")\n","    joblib.dump(prep_train_img_files_save[split_index:], root+\"/prep_test_img_files_save_20\")\n","    joblib.dump(prep_train_label_files_save[split_index:], root+\"/prep_test_label_files_save_20\")\n","    clear_output()\n","    return True\n","\n","# Invoke based on choice \n","if __name__ == '__main__' and Choice>1 : \n","    Indicator=Train_Test_Split()\n","    if Indicator:print(\"Data Train_Test_Split Successful Done!\")\n","\n","elif __name__ != '__main__':print(\"4.Data Train_Test_Split      .. .. .. >>> |Done| <4/5>\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Data Train_Test_Split Successful Done!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0Syd3NOUUhnS"},"source":["## Data Generator to generate samples from raw data"]},{"cell_type":"code","metadata":{"id":"TLpwiavLfOuB"},"source":["# Generate data from disk which is prepared along with each batch during Training \n","height,width,n_classes=240,480,7\n","def image_generator_d(data,batch_files,start,end):\n","    '''\n","    Function to prepare data and generate samples for each batch during training\n","    This function is called recursively for each batch in each epoch\n","    \n","    Input\n","    data<String>         : Absolute Path of Data Directory\n","    batch_files<Float>   : Contain data files names for a batch\n","    start<Integer>       : Start index value of sample for that batch\n","    end <Integer>        : End index value of sample for that batch\n","    \n","    Return\n","    image<Array>      : Data matrix for that Batch  \n","    '''\n","    image=[]\n","    for i in range(len(batch_files)):\n","        img = cv2.imread(data+batch_files[i])\n","        img = cv2.resize(img,(width,height))\n","        img = np.float32(img)/255\n","        image.append(img)\n","    image=np.array(image)\n","    return image\n","\n","def label_generator_d(data,batch_files,start,end):\n","    '''\n","    Function to prepare Label mask and generate samples for each batch during training\n","    This function is called recursively for each batch in each epoch\n","    \n","    Input\n","    data<String>         : Absolute Path of Mask Directory\n","    batch_files<Float>   : Contain data files names for a batch\n","    start<Integer>       : Start index value of sample for that batch\n","    end <Integer>        : End index value of sample for that batch\n","    \n","    Return\n","    labels<Array>      : Label matrix for that Batch  \n","    '''\n","    labels=[]\n","    for i in range(len(batch_files)):\n","        label = np.zeros((height, width, n_classes)).astype(np.uint8)\n","        img = cv2.imread(data+batch_files[i])\n","        img = cv2.resize(img,(width,height))\n","        img1 = img[:,:,0]\n","        for i in range(n_classes):\n","            label[:,:,i] = (img1==i).astype(np.uint8)\n","        labels.append(label)\n","    labels=np.array(labels)\n","    return labels\n","\n","def train_batch_generator_d(batch_size,epochs):\n","    '''\n","    Function to get prepared train data for training for each batch\n","    This function is recursively calls image and label generator for each batch\n","\n","    Input\n","    epochs<Integer>       : Number of epochs to train\n","    batch_size<Integer>   : Training batch size\n","    \n","    Return\n","    (batch_x, batch_y)    : Yield images and labels for each batch  \n","    '''\n","    \n","    global train_img_path1,train_label_path1, train_img_path2,train_label_path2\n","    tr_L = len(train_img_files1)+len(train_img_files2)  # number of total data files\n","    num_tr=0\n","    \n","    while num_tr<epochs*2 :    # while loop to run for specified epoch\n","        train_batch_start=0\n","        train_batch_end = batch_size\n","        \n","        while train_batch_start < tr_L:    # while loop to run for Total number of samples\n","            train_limit = min(train_batch_end, tr_L)\n","            \n","            if train_limit<len(train_img_files1):    # Get train data from part1\n","                train_img_path,train_img_files,train_label_path,train_label_files,train_offset_start,train_offset_limit=train_img_path1,train_img_files1,train_label_path1,train_label_files1,0,0\n","                \n","            elif train_limit>len(train_img_files1) and train_limit<(len(train_img_files1)+batch_size):    # Get train data from end of part1 and start of part2\n","                train_limit,train_batch_start,train_offset_start,train_offset_limit=len(train_img_files1),len(train_img_files1)-batch_size,0,0\n","            \n","            elif train_limit>len(train_img_files1) and train_limit>=(len(train_img_files1)+batch_size):   # Get train data from part2\n","                train_img_path,train_img_files,train_label_path,train_label_files=train_img_path2,train_img_files2,train_label_path2,train_label_files2\n","                train_offset_start=train_offset_limit=len(train_img_files)\n","            \n","            # Call Image and label Generator for batch_size number of prepared train Samples\n","            batch_x = image_generator_d(train_img_path,train_img_files[train_batch_start-train_offset_start:(train_batch_start-train_offset_start+batch_size)],train_batch_start-train_offset_start,(train_batch_start-train_offset_start+batch_size)) \n","            batch_y = label_generator_d(train_label_path,train_label_files[train_batch_start-train_offset_start:(train_batch_start-train_offset_start+batch_size)],train_batch_start-train_offset_start,(train_batch_start-train_offset_start+batch_size))\n","            yield (batch_x,batch_y)          # yield X,Y for training for each batch\n","            train_batch_start += batch_size   \n","            train_batch_end += batch_size    # reinitialize start and end for next batch \n","        num_tr+=1\n","\n","def val_batch_generator_d(batch_size,epochs):\n","    '''\n","    Function to get prepared Validation data for training for each batch\n","    This function is recursively calls image and label generator for each batch in each epoch\n","\n","    Input\n","    epochs<Integer>       : Number of epochs to train\n","    batch_size<Integer>   : Training batch size\n","    \n","    Return\n","    (batch_x, batch_y)    : Yield images and labels for each batch  \n","    '''\n","    global val_img_path1,val_label_path1, val_img_path2,val_label_path2\n","    val_L = len(val_img_files1)+len(val_img_files2)  # number of total val data files\n","    num_val=0\n","    \n","    while num_val<epochs*2:    # while loop to run for specified epoch\n","        val_batch_start,val_batch_end=0,batch_size    \n","\n","        if get_gpu_memory_status()>25.25:       \n","            get_gpu_memory_status(True)    # raise error if RAM is almost full\n","            raise Exception(\"Ram Almost Full\")\n","        \n","        while val_batch_start < val_L:    # while loop to run for Total number of samples\n","            val_limit = min(val_batch_end, val_L)\n","            \n","            if val_limit<len(val_img_files1):    # Get val data from part1\n","                val_img_path,val_img_files,val_label_path,val_label_files,val_offset_start,val_offset_limit=val_img_path1,val_img_files1,val_label_path1,val_label_files1,0,0\n","            \n","            elif val_limit>len(val_img_files1) and val_limit<(len(val_img_files1)+batch_size):  # Get val data from end of part1 and start of part2\n","                val_limit,val_batch_start,val_offset_start,val_offset_limit=len(val_img_files1),len(val_img_files1)-batch_size,0,0\n","            \n","            elif val_limit>len(val_img_files1) and val_limit>=(len(val_img_files1)+batch_size): # Get val data from part2\n","                val_img_path,val_img_files,val_label_path,val_label_files=val_img_path2,val_img_files2,val_label_path2,val_label_files2\n","                val_offset_start=val_offset_limit=len(val_img_files1)\n","            \n","            # Call Image and label Generator for batch_size number of prepared val Samples\n","            batch_valx = image_generator_d(val_img_path,val_img_files[val_batch_start-val_offset_start:(val_batch_start-val_offset_start+batch_size)],val_batch_start-val_offset_start,(val_batch_start-val_offset_start+batch_size))\n","            batch_valy = label_generator_d(val_label_path,val_label_files[val_batch_start-val_offset_start:(val_batch_start-val_offset_start+batch_size)],val_batch_start-val_offset_start,(val_batch_start-val_offset_start+batch_size))\n","            yield (batch_valx, batch_valy)  # yield X,Y for validation each batch\n","            val_batch_start += batch_size    \n","            val_batch_end += batch_size     # reinitialize start and end for next batch \n","        num_val+=1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VFrTGKJ8UhnY"},"source":["## Data Generator to generate samples from prepared saved joblib file"]},{"cell_type":"code","metadata":{"id":"WyNTFKPsVrMv"},"source":["# Generate data for each batch from where data already prepared and saved as joblib File \n","height,width,n_classes=240,480,7\n","def image_generator_j(start,end,saved_data):\n","    '''Function to get samples from saved data for each batch in each epoch'''\n","    return np.array(saved_data[start:end])\n","\n","def label_generator_j(start,end,saved_data):\n","    '''Function to get Mask from saved data for each batch in each epoch'''\n","    slice_saved=saved_data[start:end]\n","    ar=np.empty((len(slice_saved),n_classes,height,width), dtype=np.uint8)\n","    for j in range(len(slice_saved)):\n","        for i in range(n_classes):\n","            ar[j][i]=slice_saved[j][i].todense()\n","    ar = moveaxis(ar, 1, 3)\n","    return ar\n","\n","def train_batch_generator_j(batch_size,epochs):\n","    '''Function to yield train Images and Labels for each batch from saved Joblib file'''\n","    global prep_train_img_files_save, prep_train_label_files_save\n","    tr_L = len(prep_train_img_files_save)\n","    num_tr=0\n","    while num_tr<epochs*2 :\n","        train_batch_start=0\n","        train_batch_end = batch_size\n","        while train_batch_start < tr_L:\n","            train_limit = min(train_batch_end, tr_L)\n","            batch_x = image_generator_j(train_batch_start,train_limit,prep_train_img_files_save) \n","            batch_y = label_generator_j(train_batch_start,train_limit,prep_train_label_files_save)\n","            yield (batch_x,batch_y)\n","            train_batch_start += batch_size   \n","            train_batch_end += batch_size\n","        num_tr+=1\n","\n","def val_batch_generator_j(batch_size,epochs):\n","    '''Function to yield validation Images and Labels for each batch from saved Joblib file'''\n","    global prep_val_img_files_save, prep_val_label_files_save\n","    val_L = len(prep_val_img_files_save)\n","    num_val=0\n","    while num_val<epochs*2:\n","        val_batch_start=0\n","        val_batch_end = batch_size\n","        while val_batch_start < val_L:\n","            val_limit = min(val_batch_end, val_L)\n","            batch_valx = image_generator_j(val_batch_start,val_limit,prep_val_img_files_save)\n","            batch_valy = label_generator_j(val_batch_start,val_limit,prep_val_label_files_save)\n","            yield (batch_valx,batch_valy)\n","            val_batch_start += batch_size   \n","            val_batch_end += batch_size\n","        num_val+=1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aj4FxzoHLrh0"},"source":["## Function to Compute Mean Intersection-Over-Union (MIOU) during training "]},{"cell_type":"code","metadata":{"id":"k5d4FV2uAQSt"},"source":["def Calculate_MIOU(y_val, y_pred):\n","    '''\n","    Function to compute Mean Intersection-Over-Union (MIOU) \n","    MIOU is the average of all Intersection-Over-Union (IOU = true_positive / (true_positive + false_positive + false_negative)) over all classes\n","    \n","    Input\n","    y_val<ndarray>      : True samples\n","    y_pred<ndarray>     : Predicted Samples\n","    \n","    Return\n","    MIoU<Float>         : MIOU Score\n","    \n","    '''\n","    class_iou ,n_classes=[],7\n","    y_predi = np.argmax(y_pred, axis=3)\n","    y_truei = np.argmax(y_val, axis=3)\n","    for c in range(n_classes):\n","        TP = np.sum((y_truei == c) & (y_predi == c))\n","        FP = np.sum((y_truei != c) & (y_predi == c))\n","        FN = np.sum((y_truei == c) & (y_predi != c)) \n","        IoU = TP / float(TP + FP + FN)\n","        if(float(TP + FP + FN) == 0):\n","            IoU=TP/0.001\n","        class_iou.append(IoU)\n","    MIoU=sum(class_iou)/n_classes\n","    return MIoU\n","\n","def miou( y_true, y_pred ) :\n","    '''Funtion to Wraps a miou function into a TensorFlow op that executes when needed'''\n","    score = tf.py_function( lambda y_true, y_pred : Calculate_MIOU( y_true, y_pred).astype('float32'),[y_true, y_pred],'float32')\n","    return score"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pQvPB7rVMC1V"},"source":["## Function to Configure Data based on Choice"]},{"cell_type":"code","metadata":{"id":"gIsOalzpCMlW"},"source":["# Configure function and data based on Data Generator Choice \n","root=\"/content/drive/My Drive/\"\n","prep_train_img_files_save=prep_val_img_files_save=prep_train_label_files_save=prep_val_label_files_save=None\n","Choice=joblib.load(root+\"/Colab Notebooks/Choice\")\n","\n","if Choice==1 and __name__ != '__main__':\n","    train_batch_generator, val_batch_generator = train_batch_generator_d, val_batch_generator_d\n","\n","elif Choice==2 and __name__ != '__main__':\n","    train_batch_generator, val_batch_generator = train_batch_generator_j, val_batch_generator_d\n","    prep_train_img_files_save, prep_train_label_files_save = joblib.load(root+\"/prep_train_img_files_save_part1\"),joblib.load(root+\"/prep_train_label_files_save_part1\")\n","\n","elif Choice==3 and __name__ != '__main__':\n","    train_batch_generator, val_batch_generator = train_batch_generator_j, val_batch_generator_j\n","    prep_train_img_files_save, prep_train_label_files_save = joblib.load(root+\"/prep_train_img_files_save_part1\"), joblib.load(root+\"/prep_train_label_files_save_part1\")\n","    prep_val_img_files_save, prep_val_label_files_save = joblib.load(root+\"data/prep_val_img_files_save\"), joblib.load(root+\"data/prep_val_label_files_save1\")\n","\n","if __name__ != '__main__':print(\"5.Loading Final Data         .. .. .. >>> |Done| <5/5>\\n\"+\"-\"*54)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D8O68Kr8MyqN"},"source":["## Invoke Garbage Collector"]},{"cell_type":"code","metadata":{"id":"DC4Y2DFaGj_a"},"source":["# Get memory status and Invoke Garbage Collector\n","res = get_gpu_memory_status(True)\n","collected = gc.collect() "],"execution_count":null,"outputs":[]}]}